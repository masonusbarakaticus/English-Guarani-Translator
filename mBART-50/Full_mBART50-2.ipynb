{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install datasets evaluate transformers[sentencepiece]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVNmVw8ygHKA",
        "outputId": "d133a087-4054-4d74-eb59-f3b2b22b54db"
      },
      "id": "WVNmVw8ygHKA",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (0.5.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (5.29.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8505c917-492d-4cdb-8db0-8bf940ccfe9f",
      "metadata": {
        "id": "8505c917-492d-4cdb-8db0-8bf940ccfe9f"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast, DataCollatorForSeq2Seq\n",
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In colab to allow access to files, uncomment below\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeEpUdaSgYjz",
        "outputId": "1d0055bf-efb0-4259-9d51-5fc993fca92d"
      },
      "id": "BeEpUdaSgYjz",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "387d79dd-ddcb-452e-a987-c277b0d60026",
      "metadata": {
        "id": "387d79dd-ddcb-452e-a987-c277b0d60026"
      },
      "outputs": [],
      "source": [
        "#Open English and Guarani NLLB corpus\n",
        "\n",
        "with open('/content/drive/MyDrive/NLLB/NLLB.en-gn.en', 'r') as f: # English\n",
        "    ENs = f.read().splitlines()\n",
        "with open('/content/drive/MyDrive/NLLB/NLLB.en-gn.gn', 'r') as f: # Guarani\n",
        "    GNs = f.read().splitlines()\n",
        "\n",
        "#Can be changed depending on processing capabilities\n",
        "ENs = ENs[:10000]\n",
        "GNs = GNs[:10000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "416c308b-3a36-417b-8262-c213b39e554f",
      "metadata": {
        "id": "416c308b-3a36-417b-8262-c213b39e554f"
      },
      "outputs": [],
      "source": [
        "# Create a format that the model can process\n",
        "\n",
        "data = [{\"translation\": {\"en\": en, \"gn\": gn}} for en, gn in zip(ENs, GNs)]\n",
        "raw_dataset = Dataset.from_list(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e87e8f04-fcc2-4e94-a7a5-5dfb4e669d79",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e87e8f04-fcc2-4e94-a7a5-5dfb4e669d79",
        "outputId": "f1e1c040-9199-48ac-c97b-cbcc61897b45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Set model and tokenizer\n",
        "\n",
        "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50\")\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50\")\n",
        "\n",
        "tokenizer.src_lang = \"en_XX\"\n",
        "tokenizer.tgt_lang = \"gn_XX\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "dd0520da-a2ef-4d98-b17b-d3875fa066cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "aa307bfe27534fb68991503b579f634e",
            "c4ee999d8ef641c1ac226d3db9b4b16e",
            "bb28f5117bd9422cae5cb12edc27ba7c",
            "c0012ce4bade4ec3bd47e18bd899179a",
            "b803a249697b4bd397f6d590f42f1591",
            "2fe665780a524bbf88cedf4052769cc7",
            "854da9e70dd6430baf1f633d5aa2e813",
            "76e66fce53a54c94a0fabc43633f3f3a",
            "7d23d4a1a83f4c5ab47b0bf475c43a7d",
            "67b10d448c2b40fa9e4756d8b96bdae4",
            "9d3cccf65f14469990be15c29733d256"
          ]
        },
        "id": "dd0520da-a2ef-4d98-b17b-d3875fa066cd",
        "outputId": "80085ea3-af2f-4939-a20f-167ff0abc56a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa307bfe27534fb68991503b579f634e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# map dataset\n",
        "def preprocess(examples):\n",
        "\n",
        "    inputs = [ex[\"en\"] for ex in examples[\"translation\"]]\n",
        "    targets = [ex[\"gn\"] for ex in examples[\"translation\"]]\n",
        "\n",
        "    model_inputs = tokenizer(inputs, max_length=128, padding=\"max_length\", truncation=True)\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=128, padding=\"max_length\", truncation=True)\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_dataset = raw_dataset.map(preprocess, batched=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e7d8e40-c002-4641-848f-38198559c3c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "0e7d8e40-c002-4641-848f-38198559c3c7",
        "outputId": "bc5a858b-39d6-461c-cb8a-72476e6991b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-be9d578fa9c6>:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjabu8784\u001b[0m (\u001b[33mjabu8784-cu-boulder\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250507_023548-cbc5u0nl</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jabu8784-cu-boulder/huggingface/runs/cbc5u0nl' target=\"_blank\">./mbart50-gn-model</a></strong> to <a href='https://wandb.ai/jabu8784-cu-boulder/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jabu8784-cu-boulder/huggingface' target=\"_blank\">https://wandb.ai/jabu8784-cu-boulder/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jabu8784-cu-boulder/huggingface/runs/cbc5u0nl' target=\"_blank\">https://wandb.ai/jabu8784-cu-boulder/huggingface/runs/cbc5u0nl</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# training arguments\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./mbart50-gn-model\",\n",
        "    eval_strategy=\"no\",\n",
        "    per_device_train_batch_size=8,\n",
        "    learning_rate=3e-5,\n",
        "    num_train_epochs=3,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    predict_with_generate=True,\n",
        "\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "# Trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# Train\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c4a40f62-13b1-4368-ab9e-16f6098672f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "c4a40f62-13b1-4368-ab9e-16f6098672f0",
        "outputId": "06d0b2f6-1e3b-436f-d48c-8a3eee841ea0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tokenizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-20ca669abbf0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforced_bos_token_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang_code_to_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gn_XX\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ],
      "source": [
        "model.config.forced_bos_token_id = tokenizer.lang_code_to_id[\"gn_XX\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ce5c3aa-0467-436f-b451-e3c4027b337e",
      "metadata": {
        "id": "1ce5c3aa-0467-436f-b451-e3c4027b337e"
      },
      "outputs": [],
      "source": [
        "# Individual test for if it produces anything\n",
        "\n",
        "def translate(text, max_length=64):\n",
        "    tokenizer.src_lang = \"en_XX\"\n",
        "    encoded = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
        "    generated = model.generate(**encoded, forced_bos_token_id=tokenizer.lang_code_to_id[\"gn_XX\"], max_length=max_length)\n",
        "    return tokenizer.batch_decode(generated, skip_special_tokens=True)[0]\n",
        "\n",
        "#Test it out\n",
        "translate(\"Where are you going?\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Past this point is chrF++ testing"
      ],
      "metadata": {
        "id": "7a87iYN9i8xN"
      },
      "id": "7a87iYN9i8xN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e234901-5269-4d54-b364-460e8b84fe90",
      "metadata": {
        "id": "0e234901-5269-4d54-b364-460e8b84fe90"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "chrf = evaluate.load(\"chrf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bcae5a9-413b-45ed-a75c-4036c2e9dd60",
      "metadata": {
        "id": "9bcae5a9-413b-45ed-a75c-4036c2e9dd60"
      },
      "outputs": [],
      "source": [
        "# translation widget for extra testing ###Developed by another team member###\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "import torch\n",
        "\n",
        "# === 1. Load model and tokenizer from saved directory ===\n",
        "\n",
        "\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(model_dir)\n",
        "tokenizer.src_lang = \"en_XX\"\n",
        "tokenizer.tgt_lang = \"gn_XX\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MBartForConditionalGeneration.from_pretrained(model_dir).to(device)\n",
        "\n",
        "def translate(text, max_new_tokens=64):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output_tokens = model.generate(\n",
        "            **inputs,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[\"gn_XX\"],\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            num_beams=4,\n",
        "            do_sample=False\n",
        "        )\n",
        "\n",
        "    return tokenizer.batch_decode(output_tokens, skip_special_tokens=True)[0]\n",
        "\n",
        "# UI Elements\n",
        "text_input = widgets.Text(\n",
        "    value='Where are you going?',\n",
        "    placeholder='Type a sentence...',\n",
        "    description='English:',\n",
        "    layout=widgets.Layout(width='90%')\n",
        ")\n",
        "\n",
        "output_box = widgets.Output()\n",
        "translate_button = widgets.Button(\n",
        "    description='Translate to Guarani',\n",
        "    button_style='success'\n",
        ")\n",
        "\n",
        "def on_translate_clicked(b):\n",
        "    output_box.clear_output()\n",
        "    sentence = text_input.value.strip()\n",
        "    with output_box:\n",
        "        if not sentence:\n",
        "            print(\"Please enter a sentence.\")\n",
        "        else:\n",
        "            translation = translate(sentence)\n",
        "            print(\"Guarani:\", translation)\n",
        "\n",
        "translate_button.on_click(on_translate_clicked)\n",
        "\n",
        "display(widgets.VBox([\n",
        "    text_input,\n",
        "    translate_button,\n",
        "    output_box\n",
        "]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d611fea1-2343-456e-b16c-b20537c5c1e8",
      "metadata": {
        "id": "d611fea1-2343-456e-b16c-b20537c5c1e8"
      },
      "outputs": [],
      "source": [
        "# read in test corpus Flores-200\n",
        "with open('Flores/eng_Latn.dev', 'r') as f: # English\n",
        "    ENGs = f.read().splitlines()\n",
        "with open('Flores/grn_Latn.dev', 'r') as f: # Guarani\n",
        "    GRNs = f.read().splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91e8bee0-6059-4406-b985-e2b49769122b",
      "metadata": {
        "id": "91e8bee0-6059-4406-b985-e2b49769122b"
      },
      "outputs": [],
      "source": [
        "def translate_all(source): #Translate a list of sentences\n",
        "\n",
        "    complete_translation=[]\n",
        "    for sent in source:\n",
        "        complete_translation.append(translate(sent))\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "758669d4-e6f2-4655-b76e-40dda97d5c66",
      "metadata": {
        "id": "758669d4-e6f2-4655-b76e-40dda97d5c66"
      },
      "outputs": [],
      "source": [
        "# Make a set of predictions in the form of a list\n",
        "# Make a set of references in the form of a list of lists\n",
        "predictions=translate_all(ENGs)\n",
        "references=[[sent] for sent in GRNs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69ef395e-1c08-4ad9-82f4-31173dfd9dc8",
      "metadata": {
        "id": "69ef395e-1c08-4ad9-82f4-31173dfd9dc8"
      },
      "outputs": [],
      "source": [
        "# Find chrf++ score\n",
        "results = chrf.compute(predictions=predictions, references=references, word_order=2)\n",
        "print(results)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aa307bfe27534fb68991503b579f634e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4ee999d8ef641c1ac226d3db9b4b16e",
              "IPY_MODEL_bb28f5117bd9422cae5cb12edc27ba7c",
              "IPY_MODEL_c0012ce4bade4ec3bd47e18bd899179a"
            ],
            "layout": "IPY_MODEL_b803a249697b4bd397f6d590f42f1591"
          }
        },
        "c4ee999d8ef641c1ac226d3db9b4b16e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fe665780a524bbf88cedf4052769cc7",
            "placeholder": "​",
            "style": "IPY_MODEL_854da9e70dd6430baf1f633d5aa2e813",
            "value": "Map: 100%"
          }
        },
        "bb28f5117bd9422cae5cb12edc27ba7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76e66fce53a54c94a0fabc43633f3f3a",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d23d4a1a83f4c5ab47b0bf475c43a7d",
            "value": 1000
          }
        },
        "c0012ce4bade4ec3bd47e18bd899179a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67b10d448c2b40fa9e4756d8b96bdae4",
            "placeholder": "​",
            "style": "IPY_MODEL_9d3cccf65f14469990be15c29733d256",
            "value": " 1000/1000 [00:00&lt;00:00, 3410.29 examples/s]"
          }
        },
        "b803a249697b4bd397f6d590f42f1591": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fe665780a524bbf88cedf4052769cc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "854da9e70dd6430baf1f633d5aa2e813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76e66fce53a54c94a0fabc43633f3f3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d23d4a1a83f4c5ab47b0bf475c43a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67b10d448c2b40fa9e4756d8b96bdae4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d3cccf65f14469990be15c29733d256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}